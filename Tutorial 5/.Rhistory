t.year=2017 GROUP BY t.month, l.state;"))
View(percentage)
View(percentage)
percentage = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR, t.month AS MONTH, l.state AS STATE,
(COUNT(CASE WHEN b.status='Free' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF FREE ROOMS',
(COUNT(CASE WHEN b.status='Unavailable' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF UNAVAILABLE ROOMS',
(COUNT(CASE WHEN b.status='Reserved' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF RESERVED ROOMS' FROM bookings b, time t, location l
WHERE b.time_id = t.time_id AND b.location_id = l.location_id AND
t.year=2017 GROUP BY MONTH, STATE;"))
percentage = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR, t.month AS MONTH, l.state AS STATE,
(COUNT(CASE WHEN b.status='Free' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF FREE ROOMS',
(COUNT(CASE WHEN b.status='Reserved' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF RESERVED ROOMS' FROM bookings b, time t, location l
WHERE b.time_id = t.time_id AND b.location_id = l.location_id AND
t.year=2017 GROUP BY MONTH, STATE;"))
percentage = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR, t.month AS MONTH, l.state AS STATE,
(COUNT(CASE WHEN b.status='Free' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF FREE ROOMS',
(COUNT(CASE WHEN b.status='Reserved' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF RESERVED ROOMS',
(COUNT(CASE WHEN b.status='Not Available' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF UNAVAILABLE ROOMS'  FROM bookings b, time t, location l ,
WHERE b.time_id = t.time_id AND b.location_id = l.location_id AND
t.year=2017 GROUP BY MONTH, STATE;"))
percentage = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR, t.month AS MONTH, l.state AS STATE,
(COUNT(CASE WHEN b.status='Free' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF FREE ROOMS',
(COUNT(CASE WHEN b.status='Reserved' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF RESERVED ROOMS',
(COUNT(CASE WHEN b.status='Not Available' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF UNAVAILABLE ROOMS'  FROM bookings b, time t, location l
WHERE b.time_id = t.time_id AND b.location_id = l.location_id AND
t.year= 2017 GROUP BY MONTH, STATE;"))
income = fetch(dbSendQuery(mydb, "SELECT time.year AS YEAR,
time.month AS MONTH,
location.state AS STATE,
SUM(checkout.income) AS 'INCOME OF 4 STAR HOTELS'
FROM hotel, time, location, checkout
WHERE time.year = 2005 AND hotel.category = '4 Stars' AND
time.time_id=checkout.time_id AND
hotel.hotel_id=checkout.hotel_id AND
location.location_id=checkout.location_id
GROUP BY MONTH, STATE ORDER BY YEAR;"))
head(income)
TotalCumulativeincome_4StarHotels <- sum(income$INCOME)
print(TotalCumulativeincome_4StarHotels)
Cumulativeincome_4StarHotels <- cumsum(income$INCOME)
income[, "CUMULATIVE INCOME OF 4 STAR HOTELS"] <- Cumulativeincome_4StarHotels <- cumsum(income$INCOME)
head(income)
rm(Cumulativeincome_4StarHotels)
rm(TotalCumulativeincome_4StarHotels)
View(percentage)
View(percentage)
View(income)
View(income)
income = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR,
t.month AS MONTH,
l.state AS STATE,
SUM(c.income) AS 'INCOME OF 4 STAR HOTELS'
FROM hotel, time, location, checkout
WHERE t.year = 2005 AND h.category = '4 Stars' AND
t.time_id=c.time_id AND
h.hotel_id=c.hotel_id AND
l.location_id=c.location_id
GROUP BY MONTH, STATE ORDER BY YEAR;"))
head(income)
#calculating the portion of reserved rooms, free rooms and unavailable rooms
percentage = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR, t.month AS MONTH, l.state AS STATE,
(COUNT(CASE WHEN b.status='Free' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF FREE ROOMS',
(COUNT(CASE WHEN b.status='Reserved' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF RESERVED ROOMS',
(COUNT(CASE WHEN b.status='Not Available' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF UNAVAILABLE ROOMS'  FROM bookings b, time t, location l
WHERE b.time_id = t.time_id AND b.location_id = l.location_id AND
t.year= 2017 GROUP BY MONTH, STATE;"))
percentage = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR, t.month AS MONTH, l.state AS STATE,
(COUNT(CASE WHEN b.status='Free' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF FREE ROOMS',
(COUNT(CASE WHEN b.status='Reserved' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF RESERVED ROOMS',
(COUNT(CASE WHEN b.status='Not Available' THEN 1 END)/COUNT(CASE WHEN b.status='Free' OR
b.status = 'Not Available' or
b.status = 'Reserved' THEN 1 END)*100)
AS 'PERCENTAGE OF UNAVAILABLE ROOMS'  FROM bookings b, time t, location l
WHERE b.time_id = t.time_id AND b.location_id = l.location_id AND
t.year= 2017 GROUP BY MONTH, STATE;"))
head(percentage)
income = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR,
t.month AS MONTH,
l.state AS STATE,
SUM(c.income) AS 'INCOME OF 4 STAR HOTELS'
FROM hotel, time, location, checkout
WHERE t.year = 2005 AND h.category = '4 Stars' AND
t.time_id=c.time_id AND
h.hotel_id=c.hotel_id AND
l.location_id=c.location_id
GROUP BY MONTH, STATE ORDER BY YEAR;"))
head(income)
rm(income)
income = fetch(dbSendQuery(mydb, "SELECT t.year AS YEAR,
t.month AS MONTH,
l.state AS STATE,
SUM(c.income) AS 'INCOME OF 4 STAR HOTELS'
FROM hotel, time, location, checkout
WHERE t.year = 2005 AND h.category = '4 Stars' AND
t.time_id=c.time_id AND
h.hotel_id=c.hotel_id AND
l.location_id=c.location_id
GROUP BY MONTH, STATE ORDER BY YEAR;"))
head(income)
income = fetch(dbSendQuery(mydb, "SELECT time.year AS YEAR,
time.month AS MONTH,
location.state AS STATE,
SUM(checkout.income) AS 'INCOME OF 4 STAR HOTELS'
FROM hotel, time, location, checkout
WHERE time.year = 2005 AND hotel.category = '4 Stars' AND
time.time_id=checkout.time_id AND
hotel.hotel_id=checkout.hotel_id AND
location.location_id=checkout.location_id
GROUP BY MONTH, STATE ORDER BY YEAR;"))
head(income)
TotalCumulativeincome_4StarHotels <- sum(income$INCOME)
print(TotalCumulativeincome_4StarHotels)
#second method -  by adding a column
Cumulativeincome_4StarHotels <- cumsum(income$INCOME)
income[, "CUMULATIVE INCOME OF 4 STAR HOTELS"] <- Cumulativeincome_4StarHotels <- cumsum(income$INCOME)
head(income)
install.packages("rattle.data")
library(rattle.data)
source('C:/Users/Asus/Desktop/BI/Tutorial/Tutorial 5/rattltnbclustex1.R')
library(rattle.data)
#load rattle data
data("wine",package = 'rattle.data')
head(wine)
#structure of data
str(wine)
#remove tyoe
training_set <-wine[-1]
str(training_set)
# kvalue has being set to 3
kc <- kmeans(training_set,3)
print(kc$withinss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers = i)$withinss )
}
# eg wss[2]=sum(kmeans(dataset,centers=2)$withinss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers = i)$withinss )
print(wss)
print(wss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers = i)$withinss )
}
print(wss)
library(rattle.data)
#load rattle data
data("wine",package = 'rattle.data')
head(wine)
#structure of data
str(wine)
#remove type in column
training_set <-wine[-1]
str(training_set)
# kvalue has being set to 3
kc <- kmeans(training_set,3)
print(kc$withinss)
# for loop range from 1 to 15 in i and train i value
# eg wss[2]=sum(kmeans(dataset,centers=2)$withinss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers = i)$withinss )
}
print(wss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers = i)$withinss )
}
print(wss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers=i)$withinss )
}
print(wss)
library(rattle.data)
#load rattle data
data("wine",package = 'rattle.data')
head(wine)
#structure of data
str(wine)
#remove type in column
training_set <-wine[-1]
str(training_set)
# kvalue has being set to 3
kc <- kmeans(training_set,3)
print(kc$withinss)
# for loop range from 1 to 15 in i and train i value
# eg wss[2]=sum(kmeans(dataset,centers=2)$withinss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers=i)$withinss )
}
print(wss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers=i)$withinss )
}
print(wss)
# for loop range from 1 to 15 in i and train i value
# eg wss[2]=sum(kmeans(dataset,centers=2)$withinss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers=i)$withinss )
}
print(wss)
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
#divide data to train and testing data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
setwd("F:/L6/BI")
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
#divide data to train and testing data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
#divide data to train and testing data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
setwd("F:/L6/BI/Tutorial")
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
#divide data to train and testing data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
library("neuralnet")
#generate square value of
traininginput <- as.data.frame(runif(50, min=0, max=100))
#train neural network to predict
trainingoutput <- sqrt(traininginput)
#cbd for combining columns
trainingdata <- cbind(traininginput, trainingoutput)
colnames(trainingdata) <- c("Input", "Output")
#1 hidden layer with 10 hidden nodes
nn <- neuralnet(Output~Input,trainingdata, hidden = 10)
plot(nn)
testdata <- as.data.frame((1:10)^2)
print(testdata)
net.results <- compute(nn, testdata)
ls(net.results)
print(net.results$net.result)
cleanoutput <- cbind(testdata, sqrt(testdata),
as.data.frame(net.results$net.result))
colnames(cleanoutput) <- C("Input", "Expected Output", "Neural Net Output")
print(cleanoutput)
library(rattle.data)
#load rattle data
data("wine",package = 'rattle.data')
head(wine)
#structure of data
str(wine)
#remove type in column
training_set <-wine[-1]
str(training_set)
# kvalue has being set to 3
kc <- kmeans(training_set,3)
print(kc$withinss)
# for loop range from 1 to 15 in i and train i value
# eg wss[2]=sum(kmeans(dataset,centers=2)$withinss)
wss <- 0
for (i in 1:15){
wss[i] <-
sum(kmeans(training_set, centers=i)$withinss )
}
print(wss)
#creating the plot diagram
plot(1:15,
wss,
type="b", ### "b" for both####)
xlab="Number of Clusters",
ylab="Within groups of squares")
kc <- kmeans(training_set,3)
print(kc$withinss)
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
#divide data to train and testing data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
setwd("C:/Users/Asus/Desktop/BI/Tutorial/Tutorial 5")
setwd("F:/L6/BI/Tutorial/Week 8")
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
#divide data to train and testing data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
setwd("C:/Users/Asus/Desktop/BI/Tutorial/Tutorial 5")
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
#divide data to train and testing data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
setwd("F:/L6/BI/Tutorial/Practicals/Tutorial 5")
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
#divide data to train and testing data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X)) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_name <- as.data.frame(lapply(concrete, normalize))
summary(concrete_name)
#divide data to train and testing data
concrete_train <- concrete_name[1:773, ]
concrete_test <- concrete_name[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
concrete <- read.csv("concrete.csv")
str(concrete)
summary(concrete)
normalize <- function(x){
return((x - min(x)) / (max(x)))  #zero - one scaling
}
concrete_name <- as.data.frame(lapply(concrete, normalize))
summary(concrete_name)
concrete_train <- concrete_name [1:773, ]
concrete_test <- concrete_name [774 : 1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag +ash +water + superplastic + coarseagg
+ fineagg + age, data = concrete_train)
plot(concrete_model)
concrete <- read.csv("concrete.csv")
str(concrete)
#to see summary data to preprocess mean edian ets
summary(concrete)
normalize <- function(X) {
return((X - min(X))) / (max(x) - min(X))) #zero - one scaling
}
#save preprocess data and apply mormalized data to function6 to improv process
concrete_name <- as.data.frame(lapply(concrete, normalize))
summary(concrete_name)
#divide data to train and testing data
concrete_train <- concrete_name[1:773, ]
concrete_test <- concrete_name[774:1030, ]
library(neuralnet)
set.seed(12345)
concrete_model <- neuralnet(strength ~ cement + slag + ash + water
+ superplastic + coarseagg + fineagg + age, data = concrete_train)
plot(concrete_model)
